{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e874fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the packages\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d69741d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining the class and its methods\n",
    "\n",
    "class load_check:\n",
    "    #default constructor\n",
    "    path=None\n",
    "    def __init__(self):\n",
    "        self.my_face_encodings=[]\n",
    "        self.my_face_names=[]\n",
    "\n",
    "        #For faster access resize the frame\n",
    "        self.frame_resizing = 0.25\n",
    "    \n",
    "    # Loading the images\n",
    "    def load_images_to_encode(self,image_path):\n",
    "        image_path=glob.glob(os.path.join(image_path,\"*.*\"))\n",
    "        #this will analyze all the images of given path\n",
    "        \n",
    "        #         For storing images in same path\n",
    "        path=image_path\n",
    "        print(\"Total number of images found are :\" + str(len(image_path)))\n",
    "\n",
    "\n",
    "        #Storing image encodings with their names\n",
    "\n",
    "        for img_pth in image_path:\n",
    "            img = cv2.imread(img_pth)\n",
    "\n",
    "            #Since it can only read images in RGB format so converting images to RGB format\n",
    "            rgb_image= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # using the name of file to give name to the image\n",
    "            #getting the filename \n",
    "            fname = os.path.basename(img_pth)\n",
    "            # removing the extensions from file name\n",
    "            (name,ext)= os.path.splitext(fname)\n",
    "\n",
    "            #Encoding the image\n",
    "            img_encoding = face_recognition.face_encodings(rgb_image)[0]\n",
    "            #there could be multiple images so getting the image at index 0\n",
    "\n",
    "            #Storing the name and image_encoding\n",
    "            self.my_face_encodings.append(img_encoding)\n",
    "            self.my_face_names.append(name)\n",
    "\n",
    "        print(\"Encoding Completed !!\")\n",
    "        \n",
    "    # Time to detect the faces\n",
    "    def detect_faces(self,frame):\n",
    "        #resizing the frame\n",
    "        s_frame = cv2.resize(frame , (0,0) , fx = self.frame_resizing , fy=self.frame_resizing)\n",
    "\n",
    "        # Finding faces and face encodings of current frame (image) of video and converting them to RGB format\n",
    "        rgb_s_image = cv2.cvtColor( s_frame , cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_s_image)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_s_image,face_locations)\n",
    "\n",
    "\n",
    "        # filling the face_names \n",
    "        face_names = []\n",
    "        for f_encoding in face_encodings:\n",
    "\n",
    "            #Checking for image match\n",
    "\n",
    "            matches = face_recognition.compare_faces(self.my_face_encodings,f_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "             # # If a match was found in known_face_encodings, just use the first one.\n",
    "                # if True in matches:\n",
    "                #     first_match_index = matches.index(True)\n",
    "                #     name = known_face_names[first_match_index]\n",
    "\n",
    "                # Or instead, use the known face with the smallest distance to the new face\n",
    "\n",
    "            face_distances = face_recognition.face_distance(self.my_face_encodings,f_encoding)\n",
    "            best_match = np.argmin(face_distances)\n",
    "\n",
    "            if matches[best_match] :\n",
    "                name = self.my_face_names[best_match]\n",
    "            else :\n",
    "                name = input(\"What is the name of individual in front of camera ?\\n\" )\n",
    "                self.my_face_encodings.append(f_encoding)\n",
    "                self.my_face_names.append(name)\n",
    "                to_save=cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(os.path.join(path,(name+\".png\")),frame)\n",
    "                \n",
    "                \n",
    "            face_names.append(name)\n",
    "\n",
    "        # Converting to mumpy array to adjust coordinates with frame resizing quickly\n",
    "        face_locations = np.array(face_locations)\n",
    "        face_locations = face_locations / self.frame_resizing\n",
    "        return face_locations.astype(int) , face_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c9ea1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Working Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bf2fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding faces from folder\n",
    "#Initializing\n",
    "fcs = load_check()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9a4b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images found are :2\n",
      "Encoding Completed !!\n",
      "The training time is :  1.5212433338165283  seconds\n"
     ]
    }
   ],
   "source": [
    "#Loading\n",
    "path='C:/Nakul/coding/Projects/face recognition/my project/images'\n",
    "stime=time.time()\n",
    "fcs.load_images_to_encode(path)\n",
    "print(\"The training time is : \",time.time()-stime , \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ad6fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning on the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "# 0 means the first webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc4ecd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "\n",
    "    #Detecting faces\n",
    "    face_locations , face_names = fcs.detect_faces( frame )\n",
    "\n",
    "    #finding image coordinates -> top left and bottom right\n",
    "    # making a rectangle with coordinate\n",
    "    for f_locations , f_name in zip (face_locations,face_names):\n",
    "        y1 ,x1 , y2 , x2 =f_locations[0],f_locations[1],f_locations[2],f_locations[3]\n",
    "\n",
    "        #adding a text\n",
    "        cv2.putText(frame,f_name,(x2,y1 -10) , cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 1, (255,255,255),2)\n",
    "        #making a rectangle\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(200,0,0),4)\n",
    "    cv2.imshow(\"Web Camera\" , frame)\n",
    "\n",
    "    #if you want to save those pictures for fun\n",
    "    # plt.imshow( frame)\n",
    "    # plt.imshow( frame)\n",
    "    # plt.show()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    #press escape key to quit webcam\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cffbf350",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848eb67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
